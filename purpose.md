- Adapt the idea of Prompt-CAM in file reseach.tex to a similar task: identical twin faces verification model (given two highly similar face image, tell whether they are same person or not).
- Dataset for training is the ND TWIN 2009 - 2010 dataset (captured at the Twins Days Festivals in Twinsburg, Ohio in 2009 and 2010) was preprocessed thorugh: face landmarks detected, aligned, face detection, crop into square images and ready to be resized to any size. The final training dataset structure is represented in a file called train_dataset_infor.json, which is a dictionary, with keys are person id and values are list of image paths. The minimum number of image each person is 4, maximum is 68, total image are 6182, total number of person is 353. A test dataset is in a different place with test_dataset_infor.
- There is a train_twin_pairs.json, which is a list of pairs of twin id. There is also a pair id information file for the test set, in test_twin_pairs. All infor files are in /data folder.
- I can training on two places: Local Ubuntu server with no data uploading ability (security) with two 2080Ti GPU(cuda:0, cuda:1) and Kaggle (T4 x2 or P100). The Ubuntu server has a locally hosted MLFlow service for training tracking. The MLFlow server is already deployed, just plug and play. For Kaggle, WanDB can be used for tracking, API key is in Kaggle secret keys. I want three training tracking method: MLFlow, WanDB and no tracking.
- Since 6182 images from 353 ids is not a big dataset, so I want to use the dataset to the fullest.
- I want a repo that only implement what needed, with most efficient performance, best resource usage. Distributed training if possible.
- There should have a guide to modify config to fully utilize multiple training resource (single training with one P100 or one T4 or distributed training with 2x T4). Put that guide in the normal README guide. There should be a guide on the size that I should resize my face images to. 
- Kaggle training will time out every 12 hours, so model checkpoint should be performed every epoch, and the training should can be resume from a checkpoint